{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein GAN - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch_utils; importlib.reload(torch_utils)\n",
    "from torch_utils import *\n",
    "import torch.nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import FloatTensor as FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Batchsize, image size and size of noise vector\n",
    "bs,sz,nz = 64,28,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, -1); X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train.reshape((60000, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_traint = torch.from_numpy(X_train)\n",
    "y_traint = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_traint = X_traint.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datas = torch.utils.data.TensorDataset(X_traint, y_traint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(datas, bs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(dataloader); n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " class GAN_G(nn.Module):\n",
    "        #inF: number of input features/channels\n",
    "        #outF: number of output channels\n",
    "        #kS: kernel size\n",
    "        #strd: strides\n",
    "        #p: padding\n",
    "        #uOut: Output height width of upsampling \n",
    "        #uOutF: Features output of upsampling\n",
    "        def up_block(self, uOutF, outF, uOut, kS, strd, p, bn=True):\n",
    "            upblock = nn.Sequential(\n",
    "                nn.Upsample((uOutF, uOut, uOut)),\n",
    "                nn.Conv2d(uOutF, outF, kS, strd, p, bias=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(outF)\n",
    "            )\n",
    "            return upblock\n",
    "        def __init__(self, sz, nz):\n",
    "            super(GAN_G, self).__init__()\n",
    "            self.input_height = 28\n",
    "            self.input_width = 28\n",
    "            self.input_dim = 100\n",
    "            self.output_dim = 1\n",
    "           \n",
    "\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(self.input_dim, 1024),\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1024, 128 * (self.input_height // 4) * (self.input_width // 4)),\n",
    "                nn.BatchNorm1d(128 * (self.input_height // 4) * (self.input_width // 4)),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            self.deconv = nn.Sequential(\n",
    "                nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n",
    "                nn.Sigmoid(),\n",
    "            )            \n",
    "            '''self.initial = nn.Sequential(\n",
    "            nn.Linear(nz, 512*7*7),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.BatchNorm2d(512*7*7),\n",
    "            )\n",
    "            \n",
    "            self.upblock1 = nn.Sequential(\n",
    "                nn.Conv2d(512, 64, 3, 1, 1, bias=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(64)\n",
    "            )\n",
    "            self.upblock2 = nn.Sequential(\n",
    "                nn.Conv2d(64, 32, 3, 1, 1, bias=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(32)\n",
    "            )\n",
    "            \n",
    "            self.final = nn.Sequential(\n",
    "                nn.Conv2d(32, 1, 1, bias=False),\n",
    "                nn.Tanh(),\n",
    "            )  '''\n",
    "        def forward(self, input):\n",
    "            '''x = self.initial(input)\n",
    "            x = x.view(-1, 512, 7, 7)\n",
    "            x = F.upsample(x, scale_factor=2)\n",
    "            x = self.upblock1(x)\n",
    "            x = F.upsample(x, scale_factor=2)\n",
    "            x = self.upblock2(x)\n",
    "            x = self.final(x)\n",
    "            return x'''\n",
    "            \n",
    "            x = self.fc(input)\n",
    "            x = x.view(-1, 128, (self.input_height // 4), (self.input_width // 4))\n",
    "            x = self.deconv(x)\n",
    "\n",
    "            return x      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAN_D(nn.Module):\n",
    "\n",
    "    def __init__(self, nc=1):\n",
    "        super(GAN_D, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 256, 5, 2, 0, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 5, 2, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(512*4*4, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(-1, 512*4*4)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d)): \n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = GAN_G(sz, nz).cuda()\n",
    "netG.apply(weights_init);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netD = GAN_D(1).cuda()\n",
    "netD.apply(weights_init);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'real' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9567cfa48202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'real' is not defined"
     ]
    }
   ],
   "source": [
    "fake = netG(create_noise(real.size()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Var(*parms): return Variable(FT(*parms).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_noise(b): \n",
    "    return Variable(FT(b, nz).cuda().normal_(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input placeholder\n",
    "input = Var(bs, 100)\n",
    "# Fixed noise used just for visualizing images when done\n",
    "fixed_noise = create_noise(bs)\n",
    "# The numbers 0 and -1\n",
    "one = np.array([1]*bs).astype('float32')\n",
    "one = torch.from_numpy(one).cuda()\n",
    "one = one.view(64,1)\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizerD = optim.RMSprop(netD.parameters(), lr = 1e-5)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_params = list(netG.parameters())\n",
    "D_params = list(netD.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_D(v, init_grad):\n",
    "    err = netD(v)\n",
    "    err = torch.mean(err)\n",
    "    err.backward(init_grad)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_trainable(net, val): \n",
    "    for p in net.parameters(): p.requires_grad = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(niter, first=True):\n",
    "    gen_iterations = 100\n",
    "    for epoch in tqdm(range(niter)):\n",
    "        data_iter =  iter(dataloader)\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            make_trainable(netD, True)\n",
    "            d_iters = (100 if first and (gen_iterations < 25) or gen_iterations % 500 == 0 \n",
    "                       else 5)\n",
    "            j = 0.01\n",
    "            while j < d_iters and i < n:\n",
    "                j+=1; i+=100\n",
    "                real = Variable(next(data_iter)[0].cuda())\n",
    "                input.data.resize_(real.size())\n",
    "                netD.zero_grad()\n",
    "                errD_real = netD(real)\n",
    "                \n",
    "                fake = netG(create_noise(real.size()[0]))\n",
    "                input.data.resize_(real.size()).copy_(fake.data)\n",
    "                errD_fake = netD(fake)\n",
    "                dloss = -errD_real.mean() + errD_fake.mean()\n",
    "                dloss.backward()\n",
    "                optimizerD.step()\n",
    "                for p in netD.parameters(): p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "            \n",
    "            make_trainable(netD, False)\n",
    "            netG.zero_grad()\n",
    "            errD_fake = netD(netG(create_noise(bs)))\n",
    "            gloss = -errD_fake.mean()\n",
    "            gloss.backward()\n",
    "            optimizerG.step()\n",
    "            \n",
    "            if gen_iterations % 300 == 0:\n",
    "                print('Iter-{}; D_loss: {}; G_loss: {}'\n",
    "                .format(gen_iterations, dloss.cpu().data.numpy(), gloss.cpu().data.numpy()))\n",
    "            gen_iterations += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real = Variable(next(iter(dataloader))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 101/1500 [00:28<06:36,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-300; D_loss: [-0.7304528]; G_loss: [0.27716875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 251/1500 [01:12<05:59,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-600; D_loss: [-1.3493488]; G_loss: [0.58862776]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 401/1500 [01:56<05:19,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-900; D_loss: [-1.4053316]; G_loss: [0.6061507]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 551/1500 [02:41<04:38,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1200; D_loss: [-1.4052033]; G_loss: [0.61417013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 701/1500 [03:27<03:56,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1500; D_loss: [-1.4016883]; G_loss: [0.61653864]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 851/1500 [04:11<03:12,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1800; D_loss: [-1.4118255]; G_loss: [0.61541766]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 880/1500 [04:20<03:03,  3.38it/s]"
     ]
    }
   ],
   "source": [
    "%time train(1500, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake = netG(fixed_noise).data.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(torchvision.utils.make_grid(fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one = X_train[9].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(one, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(one.ravel(),256,[0,256]); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
